---
title: "Data Cleaning"
author: "Federico Chung, Josh Upadhyay, Zuofu Huang"
date: "10/31/2019"
output: html_document
---
```{r warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(keras)
library(purrr)
library(tm)
# library(RTextTools)
library(e1071)
library(doMC)
registerDoMC(cores=detectCores())
library(stringr)
```

```{r}
buzzfeed <- read.csv("https://www.macalester.edu/~ajohns24/data/buzzfeed.csv")
```

```{r}
buzzfeed2 <- buzzfeed %>%
  mutate(text = as.character(text)) 
```

```{r}
buzzfeed2$text  <- gsub("[^0-9A-Za-z/// ]","<>" , buzzfeed2$text ,ignore.case = TRUE)
buzzfeed2$text <- gsub("<>","" , buzzfeed2$text ,ignore.case = TRUE)
```

```{r}
buzzfeed3 <- buzzfeed2 %>%
  mutate(text = as.character(text)) %>%
  mutate(text = strsplit(text, "\\s+"))
```

```{r}
#glimpse(buzzfeed)
```

```{r}
# Randomize the dataset
#set.seed(454)
#buzzfeed <- buzzfeed[sample(nrow(buzzfeed)), ]

#buzzfeed <- buzzfeed[sample(nrow(buzzfeed)), ]
#glimpse(buzzfeed)
```

```{r}
#corpus <- Corpus(VectorSource(buzzfeed$text))
```

```{r}
#corpus.clean <- corpus %>%
  #tm_map(content_transformer(tolower)) %>% 
  #tm_map(removePunctuation) %>%
  #tm_map(removeNumbers) %>%
  #tm_map(removeWords, stopwords(kind="en")) %>%
  #tm_map(stripWhitespace)
```

```{r}
#dtm <- DocumentTermMatrix(corpus.clean)
```

```{r}
#buzzfeed2 <- buzzfeed %>%
  #mutate(plain = corpus.clean[[]])
```


