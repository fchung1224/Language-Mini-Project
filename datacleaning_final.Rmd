---
title: "Data Cleaning"
author: "Federico Chung, Josh Upadhyay, Zuofu Huang"
date: "10/31/2019"
output: html_document
---
```{r warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(keras)
library(purrr)
library(tm)
library(e1071)
library(doMC)
registerDoMC(cores=detectCores())
library(stringr)
library(SentimentAnalysis)
library(searchable)
library(syuzhet)
```

### Import Data

```{r}
buzzfeed <- read.csv("https://www.macalester.edu/~ajohns24/data/buzzfeed.csv")
```

### Clean Data

```{r}
buzzfeed_clean <- buzzfeed %>%
  mutate(text = as.character(text)) %>%
  mutate(title = as.character(title))
```

```{r}
buzzfeed_clean$text  <- gsub("[^0-9A-Za-z/// ]","<>" , buzzfeed_clean$text ,ignore.case = TRUE)
buzzfeed_clean$text <- gsub("<>","" , buzzfeed_clean$text ,ignore.case = TRUE)

buzzfeed_clean$title  <- gsub("[^0-9A-Za-z/// ]","<>" , buzzfeed_clean$title ,ignore.case = TRUE)
buzzfeed_clean$title <- gsub("<>","" , buzzfeed_clean$title ,ignore.case = TRUE)
```

### wordCount

```{r}
# This sentiment function outputs the number of distinct word counts.
distinct_words <- analyzeSentiment(buzzfeed_clean$text) %>%
  select(WordCount)

buzzfeed_clean <- cbind(buzzfeed_clean, distinct_words)
```

### Sentiment

```{r}
sentiment <- get_nrc_sentiment(buzzfeed_clean$text)

buzzfeed_clean <- cbind(buzzfeed_clean, sentiment)
```

### Value manipulation

```{r}
buzzfeed_clean <- buzzfeed_clean %>%
  mutate(text = as.character(text)) %>%
  mutate(text = strsplit(text, "\\s+")) %>%
  mutate(title = as.character(title)) %>%
  mutate(title = strsplit(title, "\\s+"))
```

```{r}
buzzfeed_final <- buzzfeed_clean %>%
  mutate(text_length = lengths(text)) %>%
  mutate(title_length = lengths(title))
```

### has_Trump

```{r}
has_trump <- rep(NA, 182)

for (i in 1:182){
  if (sum(buzzfeed_final$title[[i]] == ignore.case("Trump")) > 0){
    has_trump[i] <- TRUE
  } else {
    has_trump[i] <- FALSE
  }
}

buzzfeed_final <- cbind(buzzfeed_final,has_trump) 
```

### politics

```{r}
politics <- rep(NA, 182)

for (i in 1:182){
  politics[i] <- sum(buzzfeed_final$title[[i]] == ignore.case("Trump")) + sum(buzzfeed_final$title[[i]] == ignore.case("Hillary")) + sum(buzzfeed_final$title[[i]] == ignore.case("clinton"))+ sum(buzzfeed_final$title[[i]] == ignore.case("democratic")) + sum(buzzfeed_final$title[[i]] == ignore.case("republican")) + sum(buzzfeed_final$title[[i]] == ignore.case("democratics")) + sum(buzzfeed_final$title[[i]] == ignore.case("republicans")) + sum(buzzfeed_final$title[[i]] == ignore.case("politics")) + sum(buzzfeed_final$title[[i]] == ignore.case("political")) + sum(buzzfeed_final$title[[i]] == ignore.case("president")) + sum(buzzfeed_final$title[[i]] == ignore.case("presidential"))
}

buzzfeed_final <- buzzfeed_final %>%
  mutate(politics = politics/title_length)
  # Select off sentimentGI?
```

### has_author

```{r}
has_author <- rep(NA,182)

for (i in 1:182){
  if (buzzfeed_final[i,3] == ""){
    has_author[i] <- TRUE
  } else {
    has_author[i] <- FALSE
  }
}

buzzfeed_final <- cbind(buzzfeed_final,has_author) 
```

### Manipulate in proportion of text length

```{r}
for (i in 1:182){
  for (j in 7:17){
    buzzfeed_final[i,j] <- buzzfeed_final[i,j]/buzzfeed_final[i,18]
  }
}
```

### Kick out title, text, url, authors

```{r}
buzzfeed_final <- buzzfeed_final[,-c(1:4)]
```






