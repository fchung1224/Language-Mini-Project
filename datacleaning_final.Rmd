---
title: "Data Cleaning"
author: "Federico Chung, Josh Upadhyay, Zuofu Huang"
date: "10/31/2019"
output: html_document
---
```{r warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(keras)
library(purrr)
library(tm)
library(e1071)
library(stringr)
library(SentimentAnalysis)
library(searchable)
library(syuzhet)
library(caret)
library(gridExtra)
library(randomForest)
```

### Import Data

```{r}
buzzfeed <- read.csv("https://www.macalester.edu/~ajohns24/data/buzzfeed.csv")
```

### Clean Data

```{r}
buzzfeed_clean <- buzzfeed %>%
  mutate(text = as.character(text)) %>%
  mutate(title = as.character(title))
```

```{r}
buzzfeed_clean$text  <- gsub("[^0-9A-Za-z/// ]","<>" , buzzfeed_clean$text ,ignore.case = TRUE)
buzzfeed_clean$text <- gsub("<>","" , buzzfeed_clean$text ,ignore.case = TRUE)

buzzfeed_clean$title  <- gsub("[^0-9A-Za-z/// ]","<>" , buzzfeed_clean$title ,ignore.case = TRUE)
buzzfeed_clean$title <- gsub("<>","" , buzzfeed_clean$title ,ignore.case = TRUE)
```

### wordCount

```{r}
# This sentiment function outputs the number of distinct word counts.
distinct_words <- analyzeSentiment(buzzfeed_clean$text) %>%
  select(WordCount)

buzzfeed_clean <- cbind(buzzfeed_clean, distinct_words)
```

### Sentiment

```{r}
sentiment <- get_nrc_sentiment(buzzfeed_clean$text)

buzzfeed_clean <- cbind(buzzfeed_clean, sentiment)
```

### Value manipulation

```{r}
buzzfeed_clean <- buzzfeed_clean %>%
  mutate(text = as.character(text)) %>%
  mutate(text = strsplit(text, "\\s+")) %>%
  mutate(title = as.character(title)) %>%
  mutate(title = strsplit(title, "\\s+"))
```

```{r}
buzzfeed_final <- buzzfeed_clean %>%
  mutate(text_length = lengths(text)) %>%
  mutate(title_length = lengths(title))
```

### has_Trump

```{r}
has_trump <- rep(NA, 182)

for (i in 1:182){
  if (sum(buzzfeed_final$title[[i]] == ignore.case("Trump")) > 0){
    has_trump[i] <- TRUE
  } else {
    has_trump[i] <- FALSE
  }
}

buzzfeed_final <- cbind(buzzfeed_final,has_trump) 
```

### politics

```{r}
politics <- rep(NA, 182)

for (i in 1:182){
  politics[i] <- sum(buzzfeed_final$title[[i]] == ignore.case("Trump")) + sum(buzzfeed_final$title[[i]] == ignore.case("Hillary")) + sum(buzzfeed_final$title[[i]] == ignore.case("clinton"))+ sum(buzzfeed_final$title[[i]] == ignore.case("democratic")) + sum(buzzfeed_final$title[[i]] == ignore.case("republican")) + sum(buzzfeed_final$title[[i]] == ignore.case("democratics")) + sum(buzzfeed_final$title[[i]] == ignore.case("republicans")) + sum(buzzfeed_final$title[[i]] == ignore.case("politics")) + sum(buzzfeed_final$title[[i]] == ignore.case("political")) + sum(buzzfeed_final$title[[i]] == ignore.case("president")) + sum(buzzfeed_final$title[[i]] == ignore.case("presidential"))
}

buzzfeed_final <- buzzfeed_final %>%
  mutate(politics = politics/title_length)
  # Select off sentimentGI?
```

### has_author

```{r}
has_author <- rep(NA,182)

for (i in 1:182){
  if (buzzfeed_final[i,3] == ""){
    has_author[i] <- TRUE
  } else {
    has_author[i] <- FALSE
  }
}

buzzfeed_final <- cbind(buzzfeed_final,has_author) 
```

### Manipulate in proportion of text length

```{r}
for (i in 1:182){
  for (j in 7:17){
    buzzfeed_final[i,j] <- buzzfeed_final[i,j]/buzzfeed_final[i,18]
  }
}
```

### Kick out title, text, url, authors

```{r}
buzzfeed_final <- buzzfeed_final[,-c(1:4)]
```

# Run algorithms 1: KNN

```{r}
# Set the seed
set.seed(253)

# Perform KNN
knn_model_1 <- train(
  type ~ .,
  data = buzzfeed_final,
  preProcess = c("center","scale"),
  method = "knn",
  tuneGrid = data.frame(k = c(1:19, seq(20, 100, by = 10), 182)),
  trControl = trainControl(method = "cv", number = 10, selectionFunction = "best"),
  metric = "Accuracy",
  na.action = na.omit
)
```

```{r}
knn_model_1$bestTune$k
```

```{r}
plot(knn_model_1)
```

```{r}
knn_model_1$results %>%
  filter(k == knn_model_1$bestTune$k) %>%
  summarize(Accuracy)
```

## Model 2: Tree

```{r}
set.seed(253)

tree_model_1 <- train(
  type ~ .,
  data = buzzfeed_final,
  method = "rpart",
  tuneGrid = data.frame(cp = seq(0, 0.2, length = 60)),
  trControl = trainControl(method = "cv", number = 10, selectionFunction = "best"),
  metric = "Accuracy",
  na.action = na.omit
)
```

```{r}
plot(tree_model_1)
```

```{r}
tree_model_1$results %>%
  filter(cp == tree_model_1$bestTune$cp) %>%
  summarize(Accuracy)
```

```{r}
variable_importance_tree <- data.frame(varImp(tree_model_1$finalModel)) %>% 
  mutate(predictor = rownames(.))

# Arrange predictors by importance (most to least)
variable_importance_tree %>% 
  arrange(desc(Overall)) %>% 
  head()

# Arrange predictors by importance (least to most)
variable_importance_tree %>% 
  arrange(Overall) %>% 
  head()
```



## Model 3: Forest

```{r}
set.seed(253)

tunegrid <- expand.grid(.mtry = c(2,4,9,16))

forest_model_1 <- train(
    type ~ . - source,
    data = buzzfeed_final,
    method = "rf", 
    trControl = trainControl(method = "cv", number = 10, selectionFunction = "best"),
    tuneGrid = tunegrid,
    metric = "Accuracy",
    na.action = na.omit
)
```

```{r}
plot(forest_model_1)
```

```{r}
forest_model_1$results %>%
  filter(mtry == forest_model_1$finalModel$mtry) %>%
  summarize(Accuracy)
```

```{r}
variable_importance <- data.frame(importance(forest_model_1$finalModel)) %>% 
  mutate(predictor = rownames(.))

# Arrange predictors by importance (most to least)
variable_importance %>% 
  arrange(desc(MeanDecreaseGini)) %>% 
  head()

# Arrange predictors by importance (least to most)
variable_importance %>% 
  arrange(MeanDecreaseGini) %>% 
  head()
```





